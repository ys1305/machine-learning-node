机器学习方法概论
========

1. 机器学习的对象是：具有一定的统计规律的数据。

2. 机器学习根据任务类型，可以划分为：

    *   监督学习任务：从已标记的训练数据来训练模型。 主要分为：分类任务、回归任务、序列标注任务。
    *   无监督学习任务：从未标记的训练数据来训练模型。主要分为：聚类任务、降维任务。
    *   半监督学习任务：用大量的未标记训练数据和少量的已标记数据来训练模型。
    *   强化学习任务：从系统与环境的大量交互知识中训练模型。
3. 机器学习根据算法类型，可以划分为：

    * 传统统计学习：基于数学模型的机器学习方法。包括`SVM`、逻辑回归、决策树等。

        这一类算法基于严格的数学推理，具有可解释性强、运行速度快、可应用于小规模数据集的特点。

    * 深度学习：基于神经网络的机器学习方法。包括前馈神经网络、卷积神经网络、递归神经网络等。

        这一类算法基于神经网络，可解释性较差，强烈依赖于数据集规模。但是这类算法在语音、视觉、自然语言等领域非常成功。

4. `没有免费的午餐`定理(`No Free Lunch Theorem:NFL`)：对于一个学习算法`A`，如果在某些问题上它比算法`B`好，那么必然存在另一些问题，在那些问题中`B`比`A`更好。

    因此不存在这样的算法：它在所有的问题上都取得最佳的性能。因此要谈论算法的优劣必须基于具体的学习问题。


一、基本概念
------

### 1.1 特征空间

1. 输入空间 ：所有输入的可能取值；输出空间 ：所有输出的可能取值。

    特征向量表示每个具体的输入， 所有特征向量构成特征空间。

2. 特征空间的每一个维度对应一种特征。

3. 可以将输入空间等同于特征空间，但是也可以不同。绝大多数情况下，输入空间等于特征空间。

    模型是定义在特征空间上的。


### 1.2 样本表示

1. 通常输入实例用 $\mathbf{\vec x}$ 表示，真实标记用 $\tilde y$ 表示，模型的预测值用 $\hat y$ 表示。

    具体的输入取值记作 $\mathbf {\vec x}_1,\mathbf {\vec x}_2,\cdots ；$具体的标记取值记作 $\tilde y_1,\tilde y_2,\cdots ；$具体的模型预测取值记作$ \hat y_1, \hat y_2,\cdots 。$

2. 所有的向量均为列向量，其中输入实例$ \mathbf {\vec x} $的特征向量记作 （假设特征空间为 n 维）：

    $\mathbf{\vec x}= \begin{bmatrix} x^{(1)} \\ x^{(2)} \\ \vdots\\ x^{(n)} \\ \end{bmatrix}​$

    这里$ x^{(i)}$ 为 $\mathbf {\vec x}$ 的第 $i $个特征的取值。第 $i $个输入记作 $\mathbf {\vec x}_i $，它的意义不同于 $x^{(i)} 。$

3. 训练数据由输入、标记对组成。通常训练集表示为：$\mathbb D=\{(\mathbf {\vec x}_1,\tilde y_1),(\mathbf {\vec x}_2,\tilde y_2),\cdots,(\mathbf {\vec x}_N,\tilde y_N)\} 。$

    *   输入、标记对又称作样本点。
    *   假设每对输入、标记对是独立同分布产生的。
4. 输入$\mathbf{\vec x} $和标记$ \tilde y $可以是连续的，也可以是离散的。

    *   $\tilde y $为连续的：这一类问题称为回归问题。
    *   $\tilde y $为离散的，且是有限的：这一类问题称之为分类问题。
    *   $\mathbf{\vec x} $和$ \tilde y$ 均为序列：这一类问题称为序列标注问题。

二、监督学习
------

### 2.1 监督学习

1. 监督学习中，训练数据的每个样本都含有标记，该标记由人工打标，所以称之为`监督` 。

2. 监督学习假设输入$ \mathbf{\vec x} $与标记$ \tilde y $遵循联合概率分布$ p{(\mathbf{\vec x}, y)} ，$训练数据和测试数据依联合概率分布 $p{(\mathbf{\vec x}, y)} $独立同分布产生。

    学习过程中，假定这个联合概率分布存在，但是具体定义未知。

3. 监督学习的目的在于学习一个由输入到输出的映射，该映射由模型表示。

    模型属于由输入空间到输出空间的映射的集合，该集合就是解空间。解空间的确定意味着学习范围的确定。

4. ==监督学习的模型可以为概率模型或者非概率模型==：

    *   概率模型由条件概率分布$ p(y \mid {\mathbf{\vec x}})$ 表示。
    *   非概率模型由决策函数 $y=f(\mathbf{\vec x}) $表示。
5. 监督学习分为学习和预测两个过程。

    给定训练集 $\mathbb D= \{(\mathbf {\vec x}_1,\tilde y_1),(\mathbf {\vec x}_2,\tilde y_2),\cdots,(\mathbf {\vec x}_N,\tilde y_N)\} ，$其中$ \mathbf {\vec x}_i \in \mathcal X $为输入值，$\tilde y_i \in \mathcal Y$ 是标记值。假设训练数据与测试数据是依据联合概率分布 $p(\mathbf{\vec x},y) $独立同分布的产生的。

    *   学习过程：在给定的训练集 $\mathbb D $上，通过学习训练得到一个模型。该模型表示为条件概率分布 $p(y \mid {\mathbf{\vec x}})$ 或者决策函数 $y=f(\mathbf{\vec x})$

    *   预测过程：对给定的测试样本 $\mathbf{\vec x}_{test} $，给出其预测结果：

        *   对于概率模型，其预测值为：$\hat y_{test}=\arg_y \max p(y\mid \mathbf{\vec x}_{test})$
        *   对于非概率模型，其预测值为：$\hat y_{test}=f(\mathbf{\vec x}_{test})$
6. 可以通过无监督学习来求解监督学习问题 $p(y\mid \mathbf{\vec x})：$

    *   首先求解无监督学习问题来学习联合概率分布$ p(\mathbf{\vec x},y)$
    *   然后计算：$p(y\mid \mathbf{\vec x})=\frac{p(\mathbf{\vec x},y)}{\sum_{y^{\prime}}p(\mathbf{\vec x},y^{\prime})} 。$

### 2.2 生成模型和判别模型

#### 常见模型分类

##### 生成式模型：

判别式分析
朴素贝叶斯
混合高斯模型
隐马尔科夫模型（HMM）
贝叶斯网络
Sigmoid Belief Networks
马尔可夫随机场（Markov Random Fields）
深度信念网络（DBN）

##### 判别式模型：

线性回归（Linear Regression）
逻辑斯特回归（Logistic Regression）
K近邻（KNN）
感知机
神经网络（NN）
支持向量机（SVM）
决策树
最大熵模型（maximum entropy model, MaxEnt）
高斯过程（Gaussian Process）
条件随机场（CRF）
区分度训练

boosting方法

#### 二者的区别

**决策函数$Y=f(X)​$：**你输入一个X，它就输出一个Y，这个Y与一个阈值比较，根据比较结果判定X属于哪个类别。例如两类（w1和w2）分类问题，如果Y大于阈值，X就属于类w1，如果小于阈值就属于类w2。这样就得到了该X对应的类别了。

**条件概率分布$P(Y|X)$：**你输入一个X，它通过比较它属于所有类的概率，然后输出概率最大的那个作为该X对应的类别。例如：如果$P(w_1|X)$大于$P(w_2|X)$，那么我们就认为X是属于w1类的。

1. 监督学习又分为生成方法和判别方法，所用到的模型分别称为生成模型和判别模型。

2. 生成方法 ：通过数据学习联合概率分布 $p(\mathbf{\vec x}, y) $，然后求出条件概率分布 $p(y\mid \mathbf{\vec x}) $作为预测的模型。

    即生成模型为：

    $$
    p(y\mid \mathbf{\vec x})=\frac{ p(\mathbf{\vec x}, y)} {p(\mathbf{\vec x})}
    $$

*   ==生成方法的优点==：能还原联合概率分布$ p(\mathbf{\vec x}, y) ，$收敛速度快，且当存在隐变量时只能用生成方法。
*   生成方法有：朴素贝叶斯法，隐马尔可夫链。

3. 判别方法 ：直接学习决策函数 $f(\mathbf{\vec x})$ 或者条件概率分布 $p(y\mid \mathbf{\vec x}) $的模型。

    基本思想是有限样本条件下建立判别函数，==不考虑样本的产生模型，直接研究预测模型==。典型的判别模型包括k近邻，感知机，决策树，支持向量机等。

    *   ==判别方法的优点==：直接预测，一般准确率更高，且一般比较简化问题。
    *   判别方法有：逻辑回归，决策树。

4. 二者区别的形象例子：

    再假如你的任务是识别一个语音属于哪种语言。例如对面一个人走过来，和你说了一句话，你需要识别出她说的到底是汉语、英语还是法语等。那么你可以有两种方法达到这个目的：

    1、学习每一种语言，你花了大量精力把汉语、英语和法语等都学会了，我指的学会是你知道什么样的语音对应什么样的语言。然后再有人过来对你哄，你就可以知道他说的是什么语音，你就可以骂他是“米国人还是小日本了”。（呵呵，切勿将政治掺杂在技术里面）

    2、不去学习每一种语言，你只学习这些语言模型之间的差别，然后再分类。意思是指我学会了汉语和英语等语言的发音是有差别的，我学会这种差别就好了。

    那么第一种方法就是生成方法，第二种方法是判别方法。

    生成算法尝试去找到底这个数据是怎么生成的（产生的），然后再对一个信号进行分类。基于你的生成假设，那么那个类别最有可能产生这个信号，这个信号就属于那个类别。判别模型不关心数据是怎么生成的，它只关心信号之间的差别，然后用差别来简单对给定的一个信号进行分类。

5. **生成模型和判别模型的联系**

    ==由生成模型可以得到判别模型，但由判别模型得不到生成模型==

### 2.3参数模型与非参数模型

LR是参数模型，SVM是非参数模型。

参数模型、非参数模型（以及半参数模型）的概念应该源自于统计学中。统计专业中有一门课程叫做《非参数统计》，研究的对象就是秩检验、核密度估计等。
在统计学中，参数模型通常假设总体（随机变量）服从某一个分布，该分布由一些参数确定（比如正太分布由均值和方差确定），在此基础上构建的模型称为参数模型；==非参数模型对于总体的分布不做任何假设==，只是知道总体是一个随机变量，其分布是存在的（分布中也可能存在参数），但是无法知道其分布的形式，更不知道分布的相关参数，只有在给定一些样本的条件下，能够依据非参数统计的方法进行推断。


从上述的区别中可以看出，==问题中有没有参数，并不是参数模型和非参数模型的区别==。其区别主要在于总体的分布形式是否已知。而为何强调“参数”与“非参数”，主要原因在于参数模型的分布可以有参数直接确定



【机器学习】参数和非参数机器学习算法 - 程序猿  <http://wwwbuild.net/DataScienceWeMedia/219846.html>



#### 参数机器学习算法

假设可以极大地简化学习过程，但是同样可以限制学习的内容。简化目标函数为已知形式的算法就称为参数机器学习算法。

> ==通过固定大小的参数集(与训练样本数独立)概况数据的学习模型称为参数模型。不管你给与一个参数模型多少数据，对于其需要的参数数量都没有影响。==
> — Artificial Intelligence: A Modern Approach，737页

##### 参数算法包括两部分：

**选择目标函数的形式。从训练数据中学习目标函数的系数。**

对于理解目标函数来讲，最简单的就是直线了，这就是线性回归里面采用的形式:

b0+b1<em>x1+b2</em>x2=0

其中b0、b1和b2是直线的系数，其影响直线的斜度和截距，x1和x2是两个输入变量。

把目标函数的形式假设为直线极大地简化了学习过程。那么现在，我们需要做的是估计直线的系数并且对于这个问题预测模型。

通常来说，目标函数的形式假设是对于输入变量的线性联合，于是参数机器学习算法通常被称为“线性机器学习算法”。

那么问题是，实际的未知的目标函数可能不是线性函数。它可能接近于直线而需要一些微小的调节。或者目标函数也可能完全和直线没有关联，那么我们做的假设是错误的，我们所做的近似就会导致差劲的预测结果。

**参数机器学习算法包括:**

- **逻辑回归**
- **线性成分分析**
- **感知机**

##### 参数机器学习算法有如下优点:

- 简洁：理论容易理解和解释结果
- 快速：参数模型学习和训练的速度都很快
- 数据更少：通常不需要大量的数据，在对数据的拟合不很好时表现也不错

##### 参数机器学习算法的局限性：

- 约束：以选定函数形式的方式来学习本身就限制了模型
- 有限的复杂度：通常只能应对简单的问题
- 拟合度小：实际中通常无法和潜在的目标函数吻合

#### 非参数机器学习算法

==对于目标函数形式不作过多的假设的算法称为非参数机器学习算法==。通过不做假设，算法可以自由的从训练数据中学习任意形式的函数。

> 当你拥有许多数据而先验知识很少时，非参数学习通常很有用，此时你不需要关注于参数的选取。
> — Artificial Intelligence: A Modern Approach，757页

非参数理论寻求在构造目标函数的过程中对训练数据作最好的拟合，同时维持一些泛化到未知数据的能力。同样的，它们可以拟合各自形式的函数。

对于理解非参数模型的一个好例子是**k近邻算法**，其目标是基于k个最相近的模式对新的数据做预测。这种理论对于目标函数的形式，==除了相似模式的数目以外不作任何假设。==

**一些非参数机器学习算法的例子包括：**

- **决策树，例如CART和C4.5**
- **朴素贝叶斯**
- **支持向量机**

##### 非参数机器学习算法的优势：

- 可变性：可以拟合许多不同的函数形式。
- 模型强大：对于目标函数不作假设或者作微小的假设
- 表现良好：对于预测表现可以非常好。

##### 非参数机器学习算法局限性：

- 需要更多数据：对于拟合目标函数需要更多的训练数据
- 速度慢：因为需要训练更多的参数，训练过程通常比较慢。
- 过拟合：有更高的风险发生过拟合，对于预测也比较难以解释。



##### 能不能用简明的语言解释什么是非参数（nonparametric）模型？ - 知乎  

<https://www.zhihu.com/question/22855599>



简单来说就是不对样本的总体分布做假设，直接分析样本的一类统计分析方法。

通常对样本进行统计分析的时候，首先要假设他们来自某个分布，然后用样本中的数据去estimate这个分布对应的参数，之后再做一些test之类。比如你假设某个样本来自同一个正态分布，然后用样本数据估算![\mu](https://www.zhihu.com/equation?tex=%5Cmu+)和![\sigma](https://www.zhihu.com/equation?tex=%5Csigma+)，再用估算出来的这两个值做test。

non-pararmetric则不然，不对总体分布做假设，自然也就不必estimate相应的参数。

链接：https://www.zhihu.com/question/22855599/answer/23556224

![img](https://img-blog.csdn.net/20180601222544228?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3NpbmF0XzI3NjUyMjU3/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70)



![img](https://img-blog.csdn.net/20180610212739778?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3NpbmF0XzI3NjUyMjU3/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70)





三、机器学习三要素
---------

1.  机器学习三要素：模型、策略、算法。
2.  **模型**：==假设空间==。 
    **策略**：从假设空间中选择模型的准则，也就是要最大/最小化的loss function。 
    **算法**：求解上loss function得到模型的参数的方法。

### 3.1 模型-假设空间

1. 模型定义了解空间。监督学习中，模型就是要学习的条件概率分布或者决策函数。

    模型的解空间包含了所有可能的条件概率分布或者决策函数，因此解空间中的模型有无穷多个。

    * 模型为一个条件概率分布：

        解空间为条件概率的集合： $\mathcal F=\{p \mid p(y\mid \mathbf{\vec x})\} 。$其中：$\mathbf{\vec x} \in \mathcal X , y \in \mathcal Y $为随机变量， $\mathcal X$ 为输入空间， $\mathcal Y$ 为输出空间。

        通常$ \mathcal F$是由一个参数向量$ \vec \theta=(\theta_1,\cdots,\theta_n) $决定的概率分布族： $\mathcal F=\{p\mid p_{\vec\theta}(y\mid \mathbf{\vec x}),\vec\theta \in \mathbb R^{n}\}$。其中： $p_{\vec\theta} $只与$ \vec\theta $有关，称$ \vec\theta $为参数空间。

    * 模型为一个决策函数：

        解空间为决策函数的集合：$ \mathcal F=\{f\mid y=f(\mathbf{\vec x})\} 。$其中：$ \mathbf{\vec x} \in \mathcal X, y \in \mathcal Y$ 为变量，$\mathcal X $为输入空间， $\mathcal Y $为输出空间。

        通常$ \mathcal F$是由一个参数向量$ \vec \theta=(\theta_1,\cdots,\theta_n) $决定的函数族：$ \mathcal F=\{f\mid y=f_{\vec\theta}(\mathbf{\vec x}),\vec\theta \in \mathbb R^{n}\}。$其中： $f_{\vec\theta} $只与$ \vec\theta $有关，称$ \vec\theta ​$为参数空间。

2. 解的表示一旦确定，解空间以及解空间的规模大小就确定了。

    如：一旦确定解的表示为：$ f(y) = \sum \theta_ix_i = \vec \theta \cdot \mathbf{\vec x}​$，则解空间就是特征的所有可能的线性组合，其规模大小就是所有可能的线性组合的数量。

3. 将学习过程看作一个在解空间中进行搜索的过程，搜索目标就是找到与训练集匹配的解。


### 3.2 策略

1.  策略考虑的是按照什么样的准则学习，从而定义优化目标。

#### 3.2.1 损失函数

1. 对于给定的输入$ \mathbf{\vec x} ​$，由模型预测的输出值$ \hat y ​$与真实的标记值 $\tilde y ​$可能不一致。此时，用损失函数度量错误的程度，记作$ L(\tilde y, \hat y) ​$，也称作代价函数。

2. ##### 常用损失函数：

    单个样本的损失

    ![img](https://img-blog.csdn.net/20160725111234270)

    * `0-1` 损失函数：

        $L(\tilde y, \hat y)= \begin{cases} 1, & \text{if $\hat y \ne \tilde y$} \\ 0, & \text{if $\hat y = \tilde y$ } \end{cases}$

        虽然 0-1损失能够客观的评价模型的好坏，但缺点是数学性质不是很好：不连续且导数为 0，难以优化。因此经常用连续可微的损失函数替代 。

    * 平方损失函数`MSE`：$ L(\tilde y, \hat y)=(\tilde y- \hat y)^{2}$

    * 绝对损失函数`MAE`：$ L(\tilde y,\hat y)=|\tilde y-\hat y|$

    * 对数损失函数：$ L(\tilde y,\hat y)=- \log p(\tilde y\mid \mathbf{\vec x}) 。$

        * 其物理意义是：二分类问题的真实分布与模型分布之间的交叉熵。

        * 一个简单的解释：因为样本 $(\mathbf{\vec x},\tilde y) $易经出现，所以理论上$ p(\tilde y\mid \mathbf{\vec x})=1 $。

            如果它不为 1，则说明预测存在误差。越远离1，说明误差越大。

    - Hinge损失函数Hinge Loss Function 

        对于两类分类问题，假设$y$和$f(x, θ)$的取值为${-1, +1} $
        $$
        \begin{aligned} \mathcal{L}(y, f(x, \theta)) &=\max (0,1-y f(x, \theta)) \\ & \triangleq[1-y f(x, \theta)]_{+} \end{aligned}
        $$

    - 交叉熵损失函数 Cross-Entropy Loss Function 
        $$
        H(p, q)=-\sum_{i=1}^{N} p\left(x^{(i)}\right) \log q\left(x^{(i)}\right)
        $$
        交叉熵是用来评估当前训练得到的概率分布与真实分布的差异情况，减少交叉熵损失就是在提高模型的预测准确率。其中$ p(x)$ 是指真实分布的概率，$ q(x) $是模型通过数据计算出来的概率估计.

        假设样本的标签$ y\in  \{1, · · · C \}$为离散的类别，模型$ f(x, θ) ∈ [0, 1]^C​$ 的输出为类别标签的条件概率分布，即 
        $$
        {p(y=c | \mathbf{x}, \theta)=f_{c}(\mathbf{x}, \theta)}
        $$

        $$
        f_{c}(\mathbf{x}, \theta) \in[0,1], \quad \sum_{c=1}^{C} f_{c}(\mathbf{x}, \theta)=1
        $$

        我们可以用一个 $C $维的one-hot向量$y$来表示样本标签。假设样本的标签为$k$，那么标签向量$ y$只有第 k 维的值为 1，其余元素的值都为 0。标签向量 $y$可以看作是样本标签的真实概率分布，即第 $c$维（记为 $y_c， 1 ≤ c ≤ C$）是类别为$ c$的真实概率。假设样本的类别为$ k$，那么它属于第$ k $类的概率为 1，其它类的概率为 0。 

        对于两个概率分布，一般可以用交叉熵来衡量它们的差异。标签的真实分布$ y$和模型预测分布$ f(x, θ)$之间的交叉熵为 
        $$
        \mathcal{L}(\mathbf{y}, f(\mathbf{x}, \theta))=-\sum_{c=1}^{C} y_{c} \log f_{c}(\mathbf{x}, \theta)
        $$
        因为 $y​$为 one-hot向量 
        $$
        \mathcal{L}(y, f(\mathbf{x}, \theta))=-\log f_{y}(x, \theta)
        $$
        其中 $f_y(x, θ)$可以看作真实类别 $y $的似然函数。因此，交叉熵损失函数也就是负对数似然损失函数（Negative Log-Likelihood Function） .

        二分类的交叉熵损失函数为
        $$
        L(w,b) = -\frac{1}{N} \sum_{i=1}^{N} (y^{(i)} \log {f(x^{(i)})} + ( 1- y^{(i)}) \log {(1- f(x^{(i)})}))\\
        y^{(i)} \in { 0,1 }
        $$

3. ==训练时采用的损失函数不一定是评估时的损失函数。但通常二者是一致的==。

    因为目标是需要预测未知数据的性能足够好，而不是对已知的训练数据拟合最好。


#### 3.2.2 风险函数-期望风险

风险函数（期望损失）可以度量平均意义下模型预测的好坏。也就是对于整个输入输出空间的损失函数的期望

1. 通常损失函数值越小，模型就越好。但是由于模型的输入、标记都是随机变量，遵从联合分布 $p(\mathbf{\vec x},y)，$ 因此定义风险函数为损失函数的期望：

    $$
    R_{exp}=\mathbb E_P\left[L(\tilde y, \hat y)\right]=\int_{\mathcal{X \times Y}}L(\tilde y, \hat y)p(\mathbf {\vec x},y)d\mathbf {\vec x}dy
    $$
    其中 $\mathcal{X , Y} $分别为输入空间和输出空间。

2. 学习的目标是**选择风险函数最小的模型** 。

3. 求 $R_{exp} ​$的过程中要用到 $p(\mathbf {\vec x},y) ,​$但是 $p(\mathbf {\vec x},y) ​$是未知的。

    实际上如果它已知，则可以轻而易举求得条件概率分布，也就不需要学习。

    ==期望风险是全局的，基于所有样本点损失函数最小化。期望风险是全局最优，是理想化的不可求的==


#### 3.2.3 经验风险

==模型f(x)关于**训练数据集的平均损失**称为经验风险（empirical risk）或经验损失==（empirical loss），记作Remp

1. 经验风险也叫经验损失。

    给定训练集$ \mathbb D=\{(\mathbf {\vec x}_1, \tilde y_1),(\mathbf {\vec x}_2,\tilde y_2),\cdots,(\mathbf {\vec x}_N,\tilde y_N)\}，$模型关于$ \mathbb D $的经验风险定义为：

    $R_{emp}=\frac 1{N} \sum_{i=1}^{N}L(\tilde y_i,\hat y_i)$

    经验风险最小化 (`empirical risk minimization:ERM`) 策略认为：经验风险最小的模型就是最优的模型。即：

    $$
    \min_{ f\in \mathcal{F}} \frac{1}{N}\sum_{i=1}^{N} L(\tilde y_i,f(\mathbf {\vec x}_i))
    $$

2. 经验风险是模型在$ \mathbb D​$ 上的平均损失。根据大数定律，当 $N \rightarrow \infty​$ 时$ R_{emp} \rightarrow R_{exp} ​$。

    但是由于现实中训练集中样本数量有限，甚至很小，所以需要对经验风险进行矫正。

3. ==**结构风险**是在经验风险上叠加表示模型复杂度的正则化项（或者称之为罚项）。它是为了防止过拟合而提出的。==

    给定训练集$ \mathbb D=\{(\mathbf {\vec x}_1,\tilde y_1),(\mathbf {\vec x}_2,\tilde y_2),\cdots,(\mathbf {\vec x}_N,\tilde y_N)\}，​$模型关于$ \mathbb D ​$的结构风险定义为：

    $$
    R_{srm}=\frac{1}{N} \sum_{i=1}^{N}L(\tilde y_i,\hat y_i)+\lambda J(f)
    $$
    其中：

    *   $J(f)$ 为模型复杂度，是定义在解空间$ \mathcal F $上的泛函。$ f $越复杂，则 $J(f) $越大。
    *   $\lambda \ge 0 $为系数，用于权衡经验风险和模型复杂度。

4. 结构风险最小化 (`structurel risk minimization:SRM`) 策略认为：结构风险最小的模型是最优的模型。即：

    $$
    \min_{f \in \mathcal F} \frac{1}{N} \sum_{i=1}^{N}L(\tilde y_i,f(\mathbf {\vec x}_i))+\lambda J(f)
    $$

5. 结构风险最小化策略符合奥卡姆剃刀原理：能够很好的解释已知数据，且十分简单才是最好的模型。


#### 3.2.4 极大似然估计

1. 极大似然估计就是经验风险最小化的例子。

2. 已知训练集$ \mathbb D=\{(\mathbf {\vec x}_1,\tilde y_1),(\mathbf {\vec x}_2,\tilde y_2),\cdots,(\mathbf {\vec x}_N,\tilde y_N)\}，$则出现这种训练集的概率为：$ \prod_{i=1}^{N}p(\tilde y_i\mid \mathbf {\vec x}_i) 。$

    根据$ \mathbb D$ 出现概率最大，有：

    $$
    \max \prod_{i=1}^{N}p(\tilde y_i\mid \mathbf {\vec x}_i)\rightarrow \max\sum_{i=1}^{N}\log p(\tilde y_i\mid \mathbf {\vec x}_i) \rightarrow \min \sum_{i=1}^{N}(-\log p(\tilde y_i\mid \mathbf {\vec x}_i))
    $$
    定义损失函数为：$L(\tilde y,\hat y) = -\log p(\tilde y\mid \mathbf{\vec x}) $，则有：

    $\min \sum_{i=1}^{N}(-\log p(\tilde y_i\mid \mathbf {\vec x}_i))\rightarrow \min \sum_{i=1}^{N}L(\tilde y_i,\hat y_i) \rightarrow \min \frac{1}{N}\sum_{i=1}^{N}L(\tilde y_i,\hat y_i)$

    即：==极大似然估计 = 经验风险最小化 。==


#### 3.2.5 最大后验估计

1. 最大后验估计就是结构风险最小化的例子。

2. 已知训练集$ \mathbb D=\{(\mathbf {\vec x}_1,\tilde y_1),(\mathbf {\vec x}_2,\tilde y_2),\cdots,(\mathbf {\vec x}_N,\tilde y_N)\}，$假设已知参数$ \mathbf\theta$ 的先验分布为 $g(\theta)$，则出现这种训练集的概率为：$ \prod_{i=1}^{N}p(\tilde y_i\mid \mathbf {\vec x}_i)g(\theta) 。$

    根据 $\mathbb D $出现概率最大：

    $$
    \max \prod_{i=1}^{N}p(\tilde y_i\mid \mathbf {\vec x}_i)g(\theta)\rightarrow \max\sum_{i=1}^{N}\log p(\tilde y_i\mid \mathbf {\vec x}_i)+\log g(\theta)\\ \rightarrow \min \sum_{i=1}^{N}(-\log p(\tilde y_i\mid \mathbf {\vec x}_i))+\log \frac{1}{g(\theta)}
    $$
    定义损失函数为：$L(\tilde y,\hat y) = -\log p(\tilde y\mid \mathbf{\vec x}) $；定义模型复杂度为$ J(f)=\log \frac{1}{g(\theta)} $；定义正则化系数为$ \lambda=\frac{1}{N} ​$。则有：

    $$
    \min \sum_{i=1}^{N}(-\log p (\tilde y_i\mid \mathbf {\vec x}_i))+\log \frac{1}{g(\theta)}\rightarrow \min \sum_{i=1}^{N}L(\tilde y_i,\hat y_i)+J(f)\\ \rightarrow \min \frac{1}{N}\sum_{i=1}^{N}L(\tilde y_i,\hat y_i)+\lambda J(f)
    $$
    即：最大后验估计 = 结构风险最小化。

    在李航的书中,朴素贝叶斯中，期望风险最小化准则可以得到后验概率最大化准则


### 3.3 算法

1.  算法指学习模型的具体计算方法。通常采用数值计算的方法求解，如：梯度下降法。



## 泛化误差上界定理

比较学习方法的泛化能力------比较泛化误差上界

- 性质： 样本容量增加， 泛化误差趋于0

- 假设空间容量越大， 泛化误差越大 

### 直观的理解

* * *

在有限的训练数据中得到一个规律，认为总体也是近似这个规律的，那么就能用这个规律进行预测。比如一个大罐子里装满了红球和白球，各一半，我随手抓了一把，然后根据这些红球白球的比例预测整个罐子也是这样的比例，这样做不一定很准确，但结果总是近似的，而且如果抓出的球越多，预测结果也就越可信。

上面的例子可以简单直观地理解一下预测的原理，其实还可以通过统计的方法对这个近似（用局部的规律近似总体的规律）的可信度进行概率分析。

### 将问题描述成更数学的形式：

* * *

* 损失函数（loss function）或者代价函数（cost function）度量预测错误的程度，记作$L(Y,f(x))​$。

* 期望损失（expected loss），即平均意义下的损失：  

    $$
    R_{exp}(f)=E_p[L(Y,f(X))]=\int_{\mathcal{X}\times \mathcal{Y}}L(y,f(x))P(x,y)dxdy
    $$

* 经验损失（empirical loss），是关于训练数据集的平均损失：  

    $$
    R_{emp}(f)=\frac{1}{N}\sum_{i=1}^{N}L(y_i,f(x_i))
    $$

* 根据大数定理，样本容量N趋近无穷时，经验风险趋近于期望风险：$R_{emp}(f)\approx R_{exp}(f)$，也就是说：如果模型在训练样本中的期望风险很小，那么它也能使得期望风险很小。

* 但是当样本容量N不是无穷大的时候怎么办？

### 泛化误差上界（定理）：

* * *

对==二分类==问题，当假设空间是有限个函数集合$\mathcal F=\left \{ f_1,f_2,\cdot \cdot \cdot ,f_d \right \}$时，对任意一个函数$f\in \mathcal F$，至少以概率$1-\sigma$，以下不等式成立：  

$$
R(f)\leqslant \hat{R}(f)+\varepsilon (d,N,\delta )
$$
其中，  

$$
\varepsilon (d,N,\delta )=\sqrt{\frac{1}{2N}\left ( \log d+\log\frac{1}{\delta } \right )}
$$
不等式左端$R(f)$是泛化误差，右端为泛化误差上界。泛化误差上界中，第一项是训练误差，训练误差越小，泛化误差也越小。第二项$\varepsilon (d,N,\delta )$，$N$越大，值越小，假设空间$\mathcal F $包含的函数越多，值越大。

- 训练误差越小，则泛化误差越小；

- 样本容量N越大，则训练误差与泛化误差越接近；

- 假设空间中包含的函数越多，则泛化误差上界越大。

> 这个定理可以从概率上说明使用经验风险近似期望风险的可信度，它与样本数量以及假设空间的复杂度有关。

### 上述定理可通过Hoeffding不等式来证明:

* * *

Hoeffding不等式： 
Hoeffding不等式适用于有界的随机变量。设有两两独立的一系列随机变量$X_1,...,X_n$。假设对所有的$1\leqslant i\leqslant n，X_i$都是几乎有界的变量，即满足$\mathbb{P}(X_i\in\left [ a_i,b_i \right ])=1$，那么这n个随机变量的经验期望：$\bar{X}=\frac{X_1+\cdot \cdot \cdot +X_n}{n}​$满足以下不等式：
$$
\mathbb{P}(\bar{X}-\mathbb{E}\left [ \bar{X} \right ]\geq t)\leq\exp (-\frac{2t^2n^2}{\sum _{i=1}^n(b_i-a_i)^2})\\
\mathbb{P}(\left |\bar{X}-\mathbb{E}\left [ \bar{X} \right ]  \right |\geq t)\leq 2\, exp (-\frac{2t^2n^2}{\sum _{i=1}^n(b_i-a_i)^2})
$$

* * *

对任意函数$f\in \mathcal F，\hat {R}(f) $是N个独立随机变量$L(Y,f(X))$的样本均值（经验期望），$R(f)​$是期望，如果损失函数取之区间为[0, 1]，则根据上述Hoeffding不等式，得到：  

$$
P(R(f)-\hat{R}(f)\geqslant \varepsilon )\leqslant \exp (-2N \epsilon ^2)
$$

由于$\mathcal F =\left \{ f_1,f_2,...,f_d \right \} ​$是一个有限集合，容易得到：  

$P(R(f)-\hat{R}(f)\geqslant \varepsilon )\leqslant d \exp (-2N \epsilon ^2)  $
令  
$$
δ=dexp(−2Nε^2)δ=dexp⁡(−2Nε^2)\\

\delta =d \exp(-2N\varepsilon ^2)
$$

然后就得到了：  
$$
P(R(f)<R^(f)+ε)⩾1−δP(R(f)<R^(f)+ε)⩾1−δ\\

P(R(f)< \hat{R}(f)+ \varepsilon )\geqslant 1-\delta
$$
上面的讨论只是假设空间包含有限个函数的情况下的泛化误差上界，对于一般的假设空间要找到泛化误差界应该就没这么简单了。
